{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd087f9c2987d76ccc83ed4d9e64503fb1224433dd8ec72f95a54cd89fff4c5ed9c",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyvis.network import Network\n",
    "\n",
    "import networkx as nx\n",
    "file_path = \"./Wihardja/wihardja_\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "compiled_df = pd.read_csv(\"../Clean Data/clean_consolidated_wihardja (forum).csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Author', 'Body', 'Reply to', 'Message Replying to',\n",
       "       'Permalink', 'Score', 'TimeStamp', 'Year', 'Source'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 254
    }
   ],
   "source": [
    "compiled_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Singapore Expat', 'HWZ']"
      ]
     },
     "metadata": {},
     "execution_count": 255
    }
   ],
   "source": [
    "list(compiled_df[\"Source\"].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "hwz_df = compiled_df[compiled_df[\"Source\"] == \"HWZ\"]\n",
    "reddit_df = compiled_df[compiled_df[\"Source\"] == \"Reddit\"]\n",
    "expat_df = compiled_df[compiled_df[\"Source\"] == \"Singapore Expat\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(6, 10)\n(0, 10)\n(1, 10)\n"
     ]
    }
   ],
   "source": [
    "print(hwz_df.shape)\n",
    "print(reddit_df.shape)\n",
    "print(expat_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "americanhippo    1\n",
       "karagiselle      1\n",
       "Mr.Canberra      1\n",
       "The_King         1\n",
       "Name: Reply to, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 258
    }
   ],
   "source": [
    "hwz_df[\"Reply to\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [author for author in hwz_df[\"Author\"].values] + [reply_to for reply_to in hwz_df[\"Reply to\"].values]\n",
    "nodes = [node for node in nodes if type(node) == str]\n",
    "\n",
    "edges = [(author, reply_to) for author, reply_to in hwz_df[[\"Author\", \"Reply to\"]].values]\n",
    "edges = [edge for edge in edges if (type(edge[0]) == str and type(edge[1]) == str)]\n",
    "pairwise_weight = {edge: 1 for edge in edges }\n",
    "for indexOuter, itemOuter in enumerate(pairwise_weight):\n",
    "    leftO, rightO = itemOuter\n",
    "    for indexInner, itemInner in enumerate(pairwise_weight):\n",
    "        leftI, rightI = itemInner\n",
    "        if indexInner > indexOuter and leftO == rightI and rightO == leftI:\n",
    "            pairwise_weight[itemInner] += 1\n",
    "            pairwise_weight[itemOuter] = 0\n",
    "\n",
    "pairwise_weight = {key: pairwise_weight[key] for key in pairwise_weight if pairwise_weight[key] > 0}\n",
    "weighted_edges = [(key[0], key[1], pairwise_weight[key]*10 ) for key in pairwise_weight]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(weighted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = Network('1000px', '1000px')\n",
    "# populates the nodes and edges data structures\n",
    "\n",
    "nt.from_nx(G)\n",
    "nt.show(file_path+'hwz_network.html')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Series([], Name: Reply to, dtype: int64)"
      ]
     },
     "metadata": {},
     "execution_count": 263
    }
   ],
   "source": [
    "reddit_df[\"Reply to\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "G= nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [author for author in reddit_df[\"Author\"].values] + [reply_to for reply_to in reddit_df[\"Reply to\"].values]\n",
    "nodes = [node for node in nodes if type(node) == str or node.strip() != \"-\"]\n",
    "\n",
    "edges = [(author, reply_to) for author, reply_to in reddit_df[[\"Author\", \"Reply to\"]].values]\n",
    "edges = [edge for edge in edges if (type(edge[0]) == str and type(edge[1]) == str and edge[0].strip() != \"-\" and edge[1].strip() != \"-\")]\n",
    "pairwise_weight = {edge: 1 for edge in edges }\n",
    "for indexOuter, itemOuter in enumerate(pairwise_weight):\n",
    "    leftO, rightO = itemOuter\n",
    "    for indexInner, itemInner in enumerate(pairwise_weight):\n",
    "        leftI, rightI = itemInner\n",
    "        if indexInner > indexOuter and leftO == rightI and rightO == leftI:\n",
    "            pairwise_weight[itemInner] += 1\n",
    "            pairwise_weight[itemOuter] = 0\n",
    "\n",
    "pairwise_weight = {key: pairwise_weight[key] for key in pairwise_weight if pairwise_weight[key] > 0}\n",
    "weighted_edges = [(key[0], key[1], pairwise_weight[key]*10 ) for key in pairwise_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(weighted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = Network('1000px', '1000px')\n",
    "# populates the nodes and edges data structures\n",
    "\n",
    "nt.from_nx(G)\n",
    "nt.hrepulsion(node_distance=50, spring_length=50)\n",
    "nt.show(file_path+'reddit_network.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Toystory    1\n",
       "Name: Reply to, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 268
    }
   ],
   "source": [
    "expat_df[\"Reply to\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "G= nx.Graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [author for author in expat_df[\"Author\"].values] + [reply_to for reply_to in expat_df[\"Reply to\"].values]\n",
    "nodes = [node for node in nodes if type(node) == str or node.strip() != \"-\"]\n",
    "\n",
    "edges = [(author, reply_to) for author, reply_to in expat_df[[\"Author\", \"Reply to\"]].values]\n",
    "edges = [edge for edge in edges if (type(edge[0]) == str and type(edge[1]) == str)]\n",
    "pairwise_weight = {edge: 1 for edge in edges }\n",
    "for indexOuter, itemOuter in enumerate(pairwise_weight):\n",
    "    leftO, rightO = itemOuter\n",
    "    for indexInner, itemInner in enumerate(pairwise_weight):\n",
    "        leftI, rightI = itemInner\n",
    "        if indexInner > indexOuter and leftO == rightI and rightO == leftI:\n",
    "            pairwise_weight[itemInner] += 1\n",
    "            pairwise_weight[itemOuter] = 0\n",
    "\n",
    "pairwise_weight = {key: pairwise_weight[key] for key in pairwise_weight if pairwise_weight[key] > 0}\n",
    "weighted_edges = [(key[0], key[1], pairwise_weight[key]*10 ) for key in pairwise_weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.add_nodes_from(nodes)\n",
    "G.add_weighted_edges_from(weighted_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "nt = Network('1000px', '1000px')\n",
    "# populates the nodes and edges data structures\n",
    "\n",
    "nt.from_nx(G)\n",
    "nt.hrepulsion(node_distance=50, spring_length=50)\n",
    "nt.show(file_path+'expat_network.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}